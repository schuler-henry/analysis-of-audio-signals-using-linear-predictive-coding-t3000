\section{Validierung}\label{sec:Validierung}
Damit sichergestellt werden kann, dass die in dieser Arbeit erarbeitete Parametrisierung von Stimmaufzeichnungen eine Aussage über die jeweilige sprechende Person ermöglicht, muss der Zusammenhang zwischen den berechneten \ac{LPC} Koeffizienten und der sprechenden Person gezeigt werden.
Dies erfolgt in der Klasse \textKlasse{FeatureEvaluator} (vgl. Quellcode~\ref{code:FeatureEvaluator}).

Hierfür wird wie bereits eingangs erwähnt ein einfaches \ac{NN} mit Hilfe der Python-Bibliothek \textKlasse{tensorflow} trainiert.
Das \ac{NN} besteht dabei aus einem Input-Layer mit 30 * 12 Features = 360 Neuronen, zwei Hidden-Layern mit je 16 Neuronen, sowie einem Output-Layer (vgl. Z.~\ref{line:NNStart}-\ref{line:NNEnd}).
Da im Output-Layer für jede Sprecher-ID ein Neuron erstellt wird, passt sich die Anzahl der Neuronen an die höchste verwendete Sprecher-ID an (vgl. Z.~\ref{line:NNOutput}).
\newline
\newline
Als Datengrundlage kommt ein von Vibhor Jain erstellter Datensatz zum Einsatz, welcher auf der Internetseite kaggle.com zur Verfügung steht und Audio-Datensätze zu 50 unterschiedlichen Sprechern bereitstellt \autocite[vgl.][]{vibhor_jain_speaker_2019}.
Für jeden Sprecher existieren dabei Aufzeichnungen mit einer Dauer von bis zu einer Stunde, welche in einminütige WAV-Dateien heruntergebrochen wurden.
Die Dateien mit Index null bis einschließlich 14 jedes Sprechers werden zum Training des \ac{NN} verwendet.
Alle Dateien ab Index 15 können somit zum Testen des \ac{NN} verwendet werden.

Für die Generierung der Trainingsdaten für das \ac{NN} wird der in Kapitel~\ref{sec:TechnischeUmsetzung} beschriebene Ablauf durchgeführt.
Dabei wird eine Blockgröße von 500 Samples mit einer Überlappung von 100 Samples gewählt.
Für die Personen 21 bis 30 werden je 1000 Chunks bestehend aus jeweils 30 aufeinanderfolgenden Frames generiert.
Da für jeden Frame zwölf Koeffizienten berechnet werden, enthält jeder Chunk somit 360 \ac{LPC} Werte.
Für eine einfach skalierbare Erstellung des Datensatzes wird die Funktion \textFunktion{create\_dataset} (vgl. Z.~\ref{line:createDatasetStart}-\ref{line:createDatasetEnd}) verwendet, welche neben dem erstellten Datensatz eine weitere Liste, die die Zuordnung des Datensatzes zu der Sprecher-ID enthält, zurückgibt.

Bevor die Trainingsdaten nun für das Training des \ac{NN} verwendet werden, werden diese gemischt, um ein besseres Trainings-Ergebnis zu erzielen (vgl. Z.~\ref{line:shuffle}).
\newline
\newline
Für die Evaluation des trainierten Modells, wird ein Test-Datensatz nach dem selben Verfahren aus den Dateien ab Index 15 für die Personen 21 bis 30 erstellt.
Somit wird zunächst sichergestellt, dass es sich bei den Testdaten um unbekannte Werte für das \ac{NN} handelt.

Mit der Funktion \textFunktion{evaluate\_model} (vgl. Z.~\ref{line:evaluateModelStart}-\ref{line:evaluateModelEnd}) kann nun die Genauigkeit, sowie die Fehlerrate des \ac{NN} ermittelt werden.
Der in dieser Arbeit verwendete Test-Datensatz wurde von dem Modell zu 70,54 Prozent korrekt vorhergesagt, bei einer Fehlerrate von 5,47.
Die Fehlerrate berechnet sich dabei nach dem categorical crossentropy Verfahren.

\begin{table}
  \centering
  \begin{tabular}{|cc*{10}{|r}|}
    \hline
    \multicolumn{2}{|c|}{}&\multicolumn{10}{c|}{\textsf{Testdaten Sprecher ID}}\\
    &             &     \textbf{21} &     \textbf{22} &     \textbf{23} &     \textbf{24} &     \textbf{25} &     \textbf{26} &     \textbf{27} &     \textbf{28} &     \textbf{29} &     \textbf{30} \\
    \hline
    & \textbf{21} &    \textbf{437} &               3 & \underline{233} & \underline{229} &              31 &               0 &               0 &               0 &               1 &               0 \\
    & \textbf{22} &               2 &    \textbf{560} &               0 &               0 &               0 &              11 &              22 &              74 &              22 &              39 \\
    & \textbf{23} & \underline{258} &               0 &    \textbf{701} &              15 &              24 &               0 &               0 &               0 &               0 &               0 \\
    & \textbf{24} &             257 &               0 &              33 &    \textbf{743} & \underline{ 33} &               0 &               0 &               0 &               0 &               0 \\
    & \textbf{25} &              46 &              12 &              33 &              13 &    \textbf{912} &               0 &               0 &               0 &               0 &               0 \\
    & \textbf{26} &               0 &              47 &               0 &               0 &               0 &    \textbf{535} & \underline{193} &              25 &              37 &              40 \\
    & \textbf{27} &               0 &              64 &               0 &               0 &               0 &             142 &    \textbf{771} &               1 &              10 &               3 \\
    & \textbf{28} &               0 & \underline{146} &               0 &               0 &               0 &             136 &               5 &    \textbf{779} &              59 & \underline{ 83} \\
    & \textbf{29} &               0 &              67 &               0 &               0 &               0 & \underline{154} &               6 &              37 &    \textbf{796} &              15 \\
    \smash{%
      \lower\dimexpr\dp\csname @arstrutbox\endcsname-\dp\strutbox+\arrayrulewidth\relax
      \hbox{\rotatebox[origin=bl]{90}{%
        \textsf{%
          %\fboxsep=-\fboxrule
          %\fbox{%
          \parbox[b]{\dimexpr 10\dp\csname @arstrutbox\endcsname+10\ht\csname @arstrutbox\endcsname\relax}{%
            \centering
            \strut Zugeordnete Sprecher ID\strut
            }%
            %}%
            }%
            }}%
            }%
            & \textbf{30} &               0 &             101 &               0 &               0 &               0 &              22 &               5 & \underline{ 84} & \underline{ 75} &    \textbf{820} \\
            \hline
            \hline
    \multicolumn{2}{|c|}{\textbf{Abstand zu 2}} & 179 & 414 &         468 &             514 &             879 &             381 &             578 &             695 &             721 &             737\\
    \hline
  \end{tabular}
  \caption{Modell Vorhersagen für 1000 Testdaten pro Sprecher}
  \label{tab:ModellPredictions}
\end{table}

Betrachtet man die Vorhersagen des Modells mittels der Funktion \textFunktion{predict} (vgl. Z.~\ref{line:predictStart}-\ref{line:predictEnd}) genauer, ergibt sich die in Tabelle~\ref{tab:ModellPredictions} dargestellte Verteilung.
Es ist zu erkennen, dass das Modell jeden Sprecher korrekt vorhergesagt hat, wobei die Zuversichtlichkeit im schlechtesten Fall 43,7 und im besten Fall 91,2 Prozent beträgt.
Zwischen dem Vorhergesagten Sprecher (fett) sowie dem Sprecher mit den zweitmeisten Vorhersagen (unterstrichen) liegt dabei im Durchschnitt ein Abstand von 55,7 Prozentpunkten.
Relativ betrachtet wird der korrekte Sprecher im Durchschnitt 4,7 Mal so oft wie der Sprecher mit den zweitmeisten Vorhersagen zugeordnet.